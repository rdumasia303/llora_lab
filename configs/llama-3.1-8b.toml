# Model Configuration for Llama 3.1 8B
model_id = "meta-llama/Llama-3.1-8B-Instruct"
description = "Meta Llama 3.1 8B Instruct"

# Quantization settings
quantization = "bitsandbytes"
load_format = "bitsandbytes"

# Model dimensions
max_model_len = 8192
max_num_seqs = 16

# Performance settings
gpu_memory_utilization = 0.99
enforce_eager = false

# Additional parameters
[additional_params]
